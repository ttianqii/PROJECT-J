# AI for Smart Cultural Experience
### PROJECT-J: AI-Powered Cross-Cultural Pronunciation Learning for Thai and Japanese Speakers

---

## Academic Paragraph

Pronunciation is one of the greatest barriers to authentic cross-cultural communication, yet learners rarely receive timely, personalised feedback outside a classroom. PROJECT-J addresses this gap by combining OpenAI Whisper for speech recognition, GPT-4o for sentence-level linguistic analysis, and a Levenshtein-distance algorithm for real-time accuracy scoring, creating an AI-driven loop in which Thai and Japanese speakers can practise each other's language and receive instant native-language feedback. Research supports this design: Golonka et al. (2014) found that technologies integrating speech recognition with corrective feedback significantly outperform passive text-based tools for pronunciation acquisition. The application also makes phonological structure visible through mora-by-mora Japanese pitch-accent maps and Thai tone-contour displays, reflecting Neri et al.'s (2002) finding that computer-assisted pronunciation training is most effective when learners can explicitly see the prosodic rules they are attempting to reproduce. Together, these AI capabilities transform an often frustrating cultural barrier into an engaging, data-driven experience that supports genuine mutual understanding between Thai and Japanese communities.

---

## APA References

Golonka, E. M., Bowles, A. R., Frank, V. M., Richardson, D. L., & Freynik, S. (2014). Technologies for foreign language learning: A review of technology types and their effectiveness. *Computer Assisted Language Learning*, *27*(1), 70–105. https://doi.org/10.1080/09588221.2012.700315

Neri, A., Cucchiarini, C., Strik, H., & Boves, L. (2002). The pedagogy-technology interface in computer assisted pronunciation training. *Computer Assisted Language Learning*, *15*(5), 441–467. https://doi.org/10.1076/call.15.5.441.13473

---

*Word count (paragraph): ~160 words*
